{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tPg_-hv_xM6j",
    "outputId": "f935c1b5-f6a9-44e4-cb9c-036eb4eb6bbb"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "import glob\n",
    "import pandas as pd\n",
    "import PySimpleGUI as sg\n",
    "from collections import defaultdict\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from gensim import models\n",
    "\n",
    "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
    "import os\n",
    "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
    "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LZjKdbwVqqUs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9SNqCkYsx5BY",
    "outputId": "4283da80-cc7e-47e2-ada4-3624f25744e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19475, 4)\n"
     ]
    }
   ],
   "source": [
    "dataf = pd.read_csv('C:/Users/LeonFremz/Desktop/profileTables.csv')\n",
    "\n",
    "print(dataf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwJY2aR2zVkK",
    "outputId": "e1859dd1-1a90-4fe0-a493-b48d150e0620"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Adaptive Filtering-Based Pseudo Open-Loop Thre...\n1        Coordinate Transformation-Free Observer-based ...\n2        Demodulation Type Single-Phase PLL with DC Off...\n3        Frequency Adaptive Parameter Estimation of Unb...\n4        Gain Normalized Adaptive Observer For Three-Ph...\n                               ...                        \n19470    A Sensitivity Approach for Eliminating Clashes...\n19471    Using parametric sensitivity analysis to detec...\n19472               Design Intent for CAD model assemblies\n19473    Implementing a maths support system for first-...\n19474    Sensitivity approach for automatically elimina...\nName: Title, Length: 19475, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datafText= dataf['Title']\n",
    "datafText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WV4rVdlhzo6l",
    "outputId": "6cc3df83-0678-4847-f687-6b9431c27590"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "#Eliminating stopwords \n",
    "#this will contain a list of all the words in the corpus\n",
    "\n",
    "datafText_words = []\n",
    "# Tokenize a paragraph into sentences and each sentence in to\n",
    "# words\n",
    "for c in datafText:\n",
    "    for sent in sent_tokenize(c):\n",
    "      word_tokens = word_tokenize(sent)\n",
    "      datafText_words += word_tokens\n",
    "\n",
    "len(datafText)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r2wv4RJX0CWf",
    "outputId": "0ef40aaf-c1d4-473d-f58b-8b3a73f2461d"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'the' is not in list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-6259a17b4a60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#inspecting the words in the datafText a bit\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdatafText_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'the'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatafText_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'The'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'the' is not in list"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "#inspecting the words in the datafText a bit\n",
    "datafText_words.index('the'), datafText_words.index('The')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6MSF4In2dKC",
    "outputId": "596555b7-b8ec-4304-e41f-ae2b565003b4"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'so' is not in list",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-fc6ab3287e2a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdatafText_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'so'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdatafText_words\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'So'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: 'so' is not in list"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "datafText_words.index('so'), datafText_words.index('So')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V4C_IhZQ40pS",
    "outputId": "6210a99d-93dd-4540-a571-3a8d6d95ffcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lower_case_words = set([ x.lower() for x in datafText_words])\n",
    "len(lower_case_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xjMiWdjo2l5z",
    "outputId": "b98b80aa-b38c-4a50-a261-00ee76d5d426"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'nltk' has no attribute 'data'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-9313bfc14e96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;31m#remove stopwords\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mstwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstopwords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#using set difference to calculate stopwords from our words\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    147\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtag\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    150\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\translate\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbleu_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentence_bleu\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mbleu\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mribes_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msentence_ribes\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mribes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmeteor_score\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmeteor_score\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmeteor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0malignment_error_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack_decoder\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mStackDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\translate\\meteor_score.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mchain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproduct\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\corpus\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLazyCorpusLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m abc = LazyCorpusLoader(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\corpus\\reader\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     54\u001b[0m \"\"\"\n\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplaintext\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\corpus\\reader\\plaintext.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mPlaintextCorpusReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCorpusReader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m     23\u001b[0m     \u001b[0mReader\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcorpora\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mconsist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mplaintext\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[1;33m.\u001b[0m  \u001b[0mParagraphs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\nltk\\corpus\\reader\\plaintext.py\u001b[0m in \u001b[0;36mPlaintextCorpusReader\u001b[1;34m()\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mfileids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m         \u001b[0mword_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mWordPunctTokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 43\u001b[1;33m         \u001b[0msent_tokenizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLazyLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tokenizers/punkt/english.pickle\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     44\u001b[0m         \u001b[0mpara_block_reader\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mread_blankline_block\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf8\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'nltk' has no attribute 'data'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "#remove stopwords\n",
    "stwords = set(stopwords.words('english'))\n",
    "#using set difference to calculate stopwords from our words\n",
    "\n",
    "stopfree_words = lower_case_words - stwords\n",
    "len(stopfree_words)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TIqR7aOq79qz",
    "outputId": "433ed077-02a2-4305-d752-6a0a6eb7c927"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18003"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Stemming\n",
    "from nltk.stem import snowball\n",
    "\n",
    "stemmer = snowball.SnowballStemmer('english')\n",
    "stemmed_words = set([stemmer.stem(x) for x in stopfree_words])\n",
    "len(stemmed_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xoRMveQD8F_h",
    "outputId": "f3cb6595-00a0-4335-d3a1-537051db1a51"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gasoline-blend',\n",
       " 'perfect',\n",
       " 'blue',\n",
       " 'phase',\n",
       " 'silicofcm',\n",
       " 'mycobacteri',\n",
       " 'disenchant',\n",
       " 'terahertz',\n",
       " 'schumpet',\n",
       " 'culturalist']"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets look at some of our words\n",
    "list(stemmed_words)[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vozWXOKE8KFh",
    "outputId": "6fe268e1-c993-47b2-9184-d3e785320274"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18003"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#constructing the index\n",
    "# Our index is a map of word -> documents it is found in\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "# We maintain the reference to the document by its index in the corpus list\n",
    "for docid, c in enumerate(datafText):\n",
    "    for sent in sent_tokenize(c):\n",
    "        for word in word_tokenize(sent):\n",
    "            word_lower = word.lower()\n",
    "            if word_lower not in stwords:\n",
    "                word_stem = stemmer.stem(word_lower)\n",
    "                # We add the document to the set againt the word in our\n",
    "                # index\n",
    "                inverted_index[word_stem].add(docid)\n",
    "\n",
    "len(inverted_index.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "P2qAzqny8kiY"
   },
   "outputs": [],
   "source": [
    "#searching using the index\n",
    "\n",
    "def process_and_search(query):\n",
    "    matched_documents = set()\n",
    "    for word in word_tokenize(query):\n",
    "        word_lower = word.lower()\n",
    "        if word_lower not in stwords:\n",
    "            word_stem = stemmer.stem(word_lower)\n",
    "            matches = inverted_index.get(word_stem)\n",
    "            if matches:\n",
    "                # The operator |= is a short hand for set union\n",
    "                matched_documents |= matches\n",
    "    return matched_documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B8dJpSkG82r0",
    "outputId": "f35cfb70-52ca-4976-a689-382dc8e64e77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{13,\n",
       " 42,\n",
       " 1101,\n",
       " 1113,\n",
       " 1119,\n",
       " 1122,\n",
       " 1925,\n",
       " 1967,\n",
       " 1969,\n",
       " 2271,\n",
       " 2273,\n",
       " 2636,\n",
       " 3139,\n",
       " 3141,\n",
       " 3149,\n",
       " 3150,\n",
       " 3156,\n",
       " 3160,\n",
       " 3166,\n",
       " 3167,\n",
       " 3169,\n",
       " 3173,\n",
       " 3174,\n",
       " 3181,\n",
       " 3196,\n",
       " 3207,\n",
       " 3213,\n",
       " 3226,\n",
       " 3227,\n",
       " 3335,\n",
       " 3337,\n",
       " 3386,\n",
       " 3707,\n",
       " 3970,\n",
       " 4138,\n",
       " 4159,\n",
       " 4185,\n",
       " 4394,\n",
       " 5136,\n",
       " 5142,\n",
       " 5238,\n",
       " 5465,\n",
       " 5552,\n",
       " 5609,\n",
       " 5634,\n",
       " 5635,\n",
       " 5658,\n",
       " 5664,\n",
       " 5775,\n",
       " 5785,\n",
       " 5798,\n",
       " 5805,\n",
       " 5808,\n",
       " 5812,\n",
       " 5975,\n",
       " 5976,\n",
       " 5981,\n",
       " 5987,\n",
       " 6012,\n",
       " 6400,\n",
       " 6423,\n",
       " 6462,\n",
       " 6594,\n",
       " 6596,\n",
       " 6951,\n",
       " 7149,\n",
       " 7495,\n",
       " 7776,\n",
       " 7943,\n",
       " 7950,\n",
       " 8198,\n",
       " 8220,\n",
       " 8223,\n",
       " 8978,\n",
       " 8983,\n",
       " 8984,\n",
       " 8987,\n",
       " 8989,\n",
       " 8994,\n",
       " 8998,\n",
       " 8999,\n",
       " 9041,\n",
       " 9050,\n",
       " 9070,\n",
       " 9077,\n",
       " 9314,\n",
       " 9364,\n",
       " 9562,\n",
       " 9626,\n",
       " 9648,\n",
       " 9978,\n",
       " 10083,\n",
       " 10805,\n",
       " 10948,\n",
       " 11364,\n",
       " 11557,\n",
       " 11933,\n",
       " 12153,\n",
       " 12165,\n",
       " 12351,\n",
       " 12489,\n",
       " 13222,\n",
       " 13229,\n",
       " 13231,\n",
       " 13233,\n",
       " 13414,\n",
       " 14058,\n",
       " 14132,\n",
       " 14253,\n",
       " 15242,\n",
       " 15243,\n",
       " 15864,\n",
       " 16029,\n",
       " 16031,\n",
       " 16059,\n",
       " 16546,\n",
       " 17014,\n",
       " 17019,\n",
       " 17031,\n",
       " 17072,\n",
       " 17295,\n",
       " 17780,\n",
       " 17928,\n",
       " 17929,\n",
       " 17930,\n",
       " 17934,\n",
       " 18079,\n",
       " 18475,\n",
       " 18477,\n",
       " 18500,\n",
       " 18503,\n",
       " 18504}"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_and_search(\"phase\")\n",
    "\n",
    "#the ouput is where the word \"phase\" appears in documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EsJsMUAO_C16",
    "outputId": "138e83ca-506c-4dae-fe9b-4fb465ffef6f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{6582, 9716, 12731, 14140}"
      ]
     },
     "execution_count": 112,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_and_search(\"blue\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hW_0wXNuALH3",
    "outputId": "e8083cfb-b85f-45fd-b662-704305ba53b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X3fdKhO44mUn"
   },
   "outputs": [],
   "source": [
    "entry = dataf.loc[0,:].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "o5kHdEip81H8",
    "outputId": "cea73e76-34f6-4eb8-be61-9e7d030053d8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name                                                      Hafiz Ahmed\n",
       "profile_URL         https://pureportal.coventry.ac.uk/en/persons/a...\n",
       "publications_url    https://pureportal.coventry.ac.uk/en/persons/a...\n",
       "Title               Adaptive Filtering-Based Pseudo Open-Loop Thre...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E1AOzyB66xnd"
   },
   "outputs": [],
   "source": [
    "def process_string(content):\n",
    "  content = content.lower() #to lowercase\n",
    "  content = content.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "id": "_6rlDnPe_yuB",
    "outputId": "5bf4f742-31f7-41be-8e28-1b5188e12a02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'adaptive filteringbased pseudo openloop threephase gridsynchronization technique '"
      ]
     },
     "execution_count": 114,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "process_string(entry.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4oRvR76A_1gI"
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
    "    tag = pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7p-I8tlASK7",
    "outputId": "6888098e-3187-4fe3-e0f0-ff7eff4a6f36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: n\n",
      " Run: v\n",
      " Happy: a\n"
     ]
    }
   ],
   "source": [
    "print(\"Apple: {}\\n Run: {}\\n Happy: {}\" .format(get_wordnet_pos(\"apple\"), get_wordnet_pos(\"run\"), get_wordnet_pos(\"happy\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tOnG_Q4oAUgI",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "dd12c81c-e4ea-4612-bd78-328cc2e5db05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "stop = stopwords.words('english')\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XFXCAYPozisR"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TPPryvtjzjQu"
   },
   "outputs": [],
   "source": [
    "#################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ohsTASUpAXWQ"
   },
   "outputs": [],
   "source": [
    "lem = WordNetLemmatizer()\n",
    "\n",
    "def stop_lemmatize(doc):\n",
    "    tokens = nltk.word_tokenize(doc)\n",
    "    tmp = \"\"\n",
    "    for w in tokens:\n",
    "        if w not in stop:\n",
    "            tmp += lem.lemmatize(w, get_wordnet_pos(w)) + \" \"\n",
    "    return tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35.0
    },
    "id": "y24xfASpAc-5",
    "outputId": "191fcad4-8958-460b-cfc5-b5f284229cb6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Adaptive Filtering-Based Pseudo Open-Loop Three-Phase Grid-Synchronization Technique '"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_lemmatize(doc = entry.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SeORviPlAfEA"
   },
   "outputs": [],
   "source": [
    "def process_string(content):\n",
    "  content = content.lower() #to lowercase\n",
    "  content = content.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
    "  content = stop_lemmatize(content)\n",
    "  return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69.0
    },
    "id": "uAMysNzCAjSs",
    "outputId": "9d376cde-7d87-4540-87e4-41be58776143"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.72 ms, sys: 0 ns, total: 4.72 ms\n",
      "Wall time: 4.83 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'adaptive filteringbased pseudo openloop threephase gridsynchronization technique '"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time process_string(entry.Title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hd-8W__sAkwO"
   },
   "outputs": [],
   "source": [
    "meta = dataf.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LBD9U03WAtXQ"
   },
   "outputs": [],
   "source": [
    "def transform_dataf(dataf):\n",
    "  dataf['Title'] = dataf['Title'].apply(process_string)\n",
    "  dataf['Name'] = dataf['Name'].apply(process_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxhPtYEUBEHx",
    "outputId": "ff4bcf2a-cddf-4864-ab51-6aef9facd666"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 39.3 s, sys: 1.67 s, total: 40.9 s\n",
      "Wall time: 40.8 s\n"
     ]
    }
   ],
   "source": [
    "%time transform_dataf(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 462.0
    },
    "id": "M7kVQ5JxBGvD",
    "outputId": "dee94201-5fed-4622-9d96-f3d48f9bbfe0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>profile_URL</th>\n",
       "      <th>publications_url</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  ...                                               text\n",
       "0  hafiz ahmed   ...  adaptive filteringbased pseudo openloop threep...\n",
       "1  hafiz ahmed   ...  coordinate transformationfree observerbased ad...\n",
       "2  hafiz ahmed   ...  demodulation type singlephase pll dc offset re...\n",
       "3  hafiz ahmed   ...  frequency adaptive parameter estimation unbala...\n",
       "4  hafiz ahmed   ...  gain normalize adaptive observer threephase sy...\n",
       "\n",
       "[5 rows x 5 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hW4zNcA8BUEi",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 748.0
    },
    "outputId": "da082c24-b9af-4c7e-db2b-3fa188d3092a"
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-53db9dd29c32>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Text'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdrop_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'profile_URL'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'publications_url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrop_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4172\u001b[0m             \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4173\u001b[0m             \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minplace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4174\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4175\u001b[0m         )\n\u001b[1;32m   4176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   3887\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3888\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3889\u001b[0;31m                 \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_drop_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_drop_axis\u001b[0;34m(self, labels, axis, level, errors)\u001b[0m\n\u001b[1;32m   3921\u001b[0m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3922\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3923\u001b[0;31m                 \u001b[0mnew_axis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3924\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0maxis_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnew_axis\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3925\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mdrop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   5285\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5286\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0merrors\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m\"ignore\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5287\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{labels[mask]} not found in axis\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5288\u001b[0m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['profile_URL' 'publications_url'] not found in axis\""
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "meta['Text'] = meta['Title'] + \" \" + meta['Name']\n",
    "drop_cols = ['profile_URL', 'publications_url']\n",
    "meta = meta.drop(drop_cols, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289.0
    },
    "id": "iD3aN865ByPl",
    "outputId": "5c66d5fa-a74a-4169-fb8a-8df123da0993"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Title</th>\n",
       "      <th>text</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  ...                                               Text\n",
       "0  hafiz ahmed   ...  adaptive filteringbased pseudo openloop threep...\n",
       "1  hafiz ahmed   ...  coordinate transformationfree observerbased ad...\n",
       "2  hafiz ahmed   ...  demodulation type singlephase pll dc offset re...\n",
       "3  hafiz ahmed   ...  frequency adaptive parameter estimation unbala...\n",
       "4  hafiz ahmed   ...  gain normalize adaptive observer threephase sy...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N3tVZUvuB3Ce"
   },
   "outputs": [],
   "source": [
    "\n",
    "def transform_dataf(dataf):\n",
    "  dataf = dataf\n",
    "  dataf['Title'] = dataf['Title'].apply(process_string)\n",
    "  dataf['Name'] = dataf['Name'].apply(process_string)\n",
    "  dataf['text'] = dataf['Title'] + \" \" + dataf['Name']\n",
    "  drop_cols = ['profile_URL', 'publications_url']\n",
    "  dataf = dataf.drop(drop_cols, axis=1)\n",
    "  return dataf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PoJ9BjpLCmGR"
   },
   "outputs": [],
   "source": [
    "#build index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wk3NflUcCr-4",
    "outputId": "e5510f4d-50bf-44e8-ee65-17decc979d86"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name                                          hafiz ahmed \n",
      "Title    adaptive filteringbased pseudo openloop threep...\n",
      "text     adaptive filteringbased pseudo openloop threep...\n",
      "Text     adaptive filteringbased pseudo openloop threep...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "entry = meta.loc[0,:].copy()\n",
    "print(entry)\n",
    "index_test = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wdifoQOfCt9v"
   },
   "outputs": [],
   "source": [
    "words = entry.Text.split()\n",
    "Text = entry.Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "83CMiWy2C9mf",
    "outputId": "bed6b717-7d98-43d0-8136-1f0a122fa8a5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adaptive': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique  hafiz ahmed ']}\n"
     ]
    }
   ],
   "source": [
    "word = words[0]\n",
    "sample = {word: [Text]}\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "npWAWPUWDDAm"
   },
   "outputs": [],
   "source": [
    "for word in words:\n",
    "  if word in index_test.keys():\n",
    "    if Title not in index_test[word]:\n",
    "      index_test[word].append(Title)\n",
    "  else:\n",
    "    index_test[word] = [Title]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nY8qh6bbDkBe",
    "outputId": "a972f4d9-6631-4dcc-a18d-035073ae6f2d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adaptive': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'filteringbased': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'pseudo': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'openloop': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'threephase': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'gridsynchronization': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'technique': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'hafiz': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'ahmed': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique ']}\n"
     ]
    }
   ],
   "source": [
    "print(index_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GGQpAdiqDoHA"
   },
   "outputs": [],
   "source": [
    "\n",
    "def index_it(entry, index):\n",
    "  words = entry.Title.split()\n",
    "  Title = entry.Title\n",
    "  for word in words:\n",
    "    if word in index.keys():\n",
    "      if Title not in index[word]:\n",
    "        index[word].append(Title)\n",
    "    else:\n",
    "      index[word] = [Title]\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6yzkF71EZiF",
    "outputId": "35dc676b-4b92-4e30-da04-107a9ae0aae7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'adaptive': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'filteringbased': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'pseudo': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'openloop': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'threephase': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'gridsynchronization': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'technique': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique ']}\n"
     ]
    }
   ],
   "source": [
    "ind = index_it(entry=entry, index= {})\n",
    "print(ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BAT84bjEb5C"
   },
   "outputs": [],
   "source": [
    "def index_all(df, index):\n",
    "  for i in range(len(df)):\n",
    "    entry = df.loc[i,:]\n",
    "    index = index_it(entry = entry, index = index)\n",
    "  return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4cyjxn2kEf15",
    "outputId": "7776beec-689a-40e6-bafc-d10cf55a26ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 43,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = index_all(meta_processed, index = {})\n",
    "len(index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C2XmiZ_bEiSu"
   },
   "outputs": [],
   "source": [
    "def build_index(dataf, index):\n",
    "    to_add = transform_df(dataf)\n",
    "    index = index_all(df = to_add, index = index)\n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kTpFdmHgE_Dj"
   },
   "outputs": [],
   "source": [
    "\n",
    "idx = build_index(dataf = dataf, index = {})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGM-dn6SFEsP",
    "outputId": "ed89b87c-a787-4f79-cc29-2304f6b0482f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19835"
      ]
     },
     "execution_count": 46,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JtFSBJnQGANr"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"/content/drive/MyDrive/information retrieval/7071CEM Information Retrieval/CW/New folder/pureportal_survey_json.json\", 'w') as fp:\n",
    "    json.dump(idx, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iLKbiGJLGg3B"
   },
   "outputs": [],
   "source": [
    "with open('/content/drive/MyDrive/information retrieval/7071CEM Information Retrieval/CW/New folder/pureportal_survey_json.json', 'r') as f:\n",
    "    pureportal_survey_json = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lQ9d65YDbYy8"
   },
   "outputs": [],
   "source": [
    "word2vec = pureportal_survey_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DPz4Pg0kLRM8",
    "outputId": "15eee5eb-59d4-4230-bbb8-eb063e88f8e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adaptive', 'filteringbased', 'pseudo', 'openloop', 'threephase', 'gridsynchronization', 'technique', 'hafiz', 'ahmed']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bVotaq36_Pxg"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Python program to generate word vectors using Word2Vec\n",
    "  \n",
    "# importing all necessary modules\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "import gensim\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "45Sk8PtP_gYk"
   },
   "outputs": [],
   "source": [
    "#  Reads ‘alice.txt’ file\n",
    "sample = open(\"/content/drive/MyDrive/information retrieval/1pureportal_survey_json.txt\", \"r\")\n",
    "s = sample.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EwddNsydASv3"
   },
   "outputs": [],
   "source": [
    "# Replaces escape character with space\n",
    "f = s.replace(\"\\n\", \" \")\n",
    "  \n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LNKDtga3AiLk"
   },
   "outputs": [],
   "source": [
    "# iterate through each sentence in the file\n",
    "for i in sent_tokenize(f):\n",
    "    temp = []\n",
    "      \n",
    "    # tokenize the sentence into words\n",
    "    for j in word_tokenize(i):\n",
    "        temp.append(j.lower())\n",
    "  \n",
    "    data.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OSaT-A2AqAh"
   },
   "outputs": [],
   "source": [
    "# Create CBOW model\n",
    "model1 = gensim.models.Word2Vec(data, min_count = 1, \n",
    "                              size = 100, window = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2q4UD1pDBunm",
    "outputId": "9d809900-bfbb-43b7-8075-fd74d3ae9c00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.TextIOWrapper name='/content/drive/MyDrive/information retrieval/1pureportal_survey_json.txt' mode='r' encoding='UTF-8'> 0.19963203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(sample, model1.similarity('vasile', 'trump'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ooYh-oG9_SHe"
   },
   "outputs": [],
   "source": [
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kJeeTBWKLb_B"
   },
   "outputs": [],
   "source": [
    "test = \"filtering based\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NiQFjQTPLn-c",
    "outputId": "882dd859-5a52-4c90-accf-4e849c8f2d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User query: filtering based.\n",
      "Normalized query: filter base .\n"
     ]
    }
   ],
   "source": [
    "print(\"User query: {}.\" .format(test))\n",
    "test_norm = process_string(test)\n",
    "print(\"Normalized query: {}.\" .format(test_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iCga9nmKLvcR"
   },
   "outputs": [],
   "source": [
    "test_split = test_norm.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AiYL5Qw7L1Pp"
   },
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "  norm = process_string(query)\n",
    "  return norm.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VocpqwHPL1V_"
   },
   "outputs": [],
   "source": [
    "retrieved = []\n",
    "for word in test_split:\n",
    "  if word in index.keys():\n",
    "    retrieved.append(index[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fxomh_a0MBhZ"
   },
   "outputs": [],
   "source": [
    "def lists_intersection(lists):\n",
    "  intersect = list(set.intersection(*map(set, lists)))\n",
    "  intersect.sort()\n",
    "  return intersect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fpeDei4sME1y",
    "outputId": "ceb93e41-47e7-4bce-8561-7b1e9a7ef9aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['adaptive filteringbased pseudo openloop threephase gridsynchronization technique ']\n"
     ]
    }
   ],
   "source": [
    "result = lists_intersection(retrieved)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AwhJ1QEBMPKY"
   },
   "outputs": [],
   "source": [
    "def search_googleish(query, index=idx):\n",
    "  query_split = process_query(query)\n",
    "  retrieved = []\n",
    "  for word in query_split:\n",
    "    if word in index.keys():\n",
    "      retrieved.append(index[word])\n",
    "  if len(retrieved)>0:\n",
    "    result = lists_intersection(retrieved)\n",
    "  else:\n",
    "      result = [0]\n",
    "  return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9m2JapAfMTWA",
    "outputId": "1d94d119-2cd6-4fea-c519-4e08e7420278"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['native american racism age donald trump historical contemporary perspective ', 'president trump christian right ']\n"
     ]
    }
   ],
   "source": [
    "result_IDs = search_googleish(\"Trump\", index)\n",
    "print(result_IDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "--zTAgIJMaqp"
   },
   "outputs": [],
   "source": [
    "#Retrieve meta-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391.0
    },
    "id": "dqw3z7c9MeJN",
    "outputId": "74829363-4e5f-4617-fe7a-d3d3181e03fb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>profile_URL</th>\n",
       "      <th>publications_url</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>coordinate transformationfree observerbased ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>demodulation type singlephase pll dc offset re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>frequency adaptive parameter estimation unbala...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hafiz ahmed</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
       "      <td>gain normalize adaptive observer threephase sy...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Name  ...                                              Title\n",
       "0  hafiz ahmed   ...  adaptive filteringbased pseudo openloop threep...\n",
       "1  hafiz ahmed   ...  coordinate transformationfree observerbased ad...\n",
       "2  hafiz ahmed   ...  demodulation type singlephase pll dc offset re...\n",
       "3  hafiz ahmed   ...  frequency adaptive parameter estimation unbala...\n",
       "4  hafiz ahmed   ...  gain normalize adaptive observer threephase sy...\n",
       "\n",
       "[5 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#in real setting we'll read the database from file here\n",
    "#meta = pd.read_csv(\"database.csv\")\n",
    "\n",
    "#this is our database\n",
    "meta = dataf.drop(['text'], axis=1).copy()\n",
    "meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c_Slc1m6Mwt6"
   },
   "outputs": [],
   "source": [
    "\n",
    "def connect_id_df(retrieved_id, dataf):\n",
    "    return dataf[dataf.Title.isin(retrieved_id)].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 213.0
    },
    "id": "faDqcHBGM6qB",
    "outputId": "97a32832-b055-4186-82fc-454ac8a26873"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>profile_URL</th>\n",
       "      <th>publications_url</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>darren reid</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/d...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/d...</td>\n",
       "      <td>native american racism age donald trump histor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chris shannahan</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/c...</td>\n",
       "      <td>https://pureportal.coventry.ac.uk/en/persons/c...</td>\n",
       "      <td>president trump christian right</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Name  ...                                              Title\n",
       "0      darren reid   ...  native american racism age donald trump histor...\n",
       "1  chris shannahan   ...                   president trump christian right \n",
       "\n",
       "[2 rows x 4 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_meta = connect_id_df(result_IDs, meta)\n",
    "result_meta.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9T7fo8SbKqJ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def average_vectors(word2vec_model, doc):\n",
    "    # remove out-of-vocabulary words\n",
    "    doc = [word for word in doc if word in word2vec_model.vocab]\n",
    "    if len(doc) == 0:\n",
    "      return np.zeros(300)\n",
    "    else:\n",
    "      return np.mean(word2vec_model[doc], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qx5T7iWCaXxy"
   },
   "outputs": [],
   "source": [
    "def cos_similarity(a, b):\n",
    "  dot = np.dot(a, b)\n",
    "  norma = np.linalg.norm(a)\n",
    "  normb = np.linalg.norm(b)\n",
    "  cos = dot / (norma * normb)\n",
    "  return(cos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323.0
    },
    "id": "441hmBr5a7mL",
    "outputId": "74548bcd-424e-4b9f-fa64-ea98eae21337"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-d2e4b0faf6ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mquery_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maverage_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_split\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-64-897101595072>\u001b[0m in \u001b[0;36maverage_vectors\u001b[0;34m(word2vec_model, doc)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# remove out-of-vocabulary words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-64-897101595072>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0maverage_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword2vec_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# remove out-of-vocabulary words\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword2vec_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'vocab'"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "query_vec = average_vectors(word2vec, test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MJXGFI5Gami5"
   },
   "outputs": [],
   "source": [
    "result_vecs = connect_id_df(result_IDs, dataf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "atksKikwabfd"
   },
   "outputs": [],
   "source": [
    "cos_sim = []\n",
    "for i in range(len(result_vecs)):\n",
    "  doc_vec = dataf.loc[i,:].drop(['profile_URL'])\n",
    "  cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "result_meta['rank'] = cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8pqTAugmWf1A"
   },
   "outputs": [],
   "source": [
    "def rank_results(query, results):\n",
    "  query_norm = process_query(query)\n",
    "  #query_vec = average_vectors(word2vec, query_norm)\n",
    "  result_vecs = connect_id_df(results.Title, meta)\n",
    "  cos_sim = []\n",
    "  for i in range(len(result_vecs)):\n",
    "    #doc_vec = result_vecs.loc[i,:].drop(['ID'])\n",
    "    cos_sim.append(cos_similarity(doc_vec, query_vec))\n",
    "    results['rank'] = cos_sim\n",
    "    results = results.sort_values('rank', axis=0)\n",
    "  return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299.0
    },
    "id": "mW_utjLdXeWD",
    "outputId": "959df217-b122-4b6d-84f3-6d74db83da03"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-1e097b37ed29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrank_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trump\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-75-6726b205b69d>\u001b[0m in \u001b[0;36mrank_results\u001b[0;34m(query, results)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult_vecs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;31m#doc_vec = result_vecs.loc[i,:].drop(['ID'])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mcos_sim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_similarity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcos_sim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rank'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc_vec' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "\n",
    "final_result = rank_results(\"Trump\", result_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FmmhuTs7Us9L"
   },
   "outputs": [],
   "source": [
    "def print_results(result_dataf):\n",
    "  for i in range(len(result_dataf)):\n",
    "    res = dataf.loc[i,:]\n",
    "    print(res.Title)\n",
    "    print(res.Name)\n",
    "    if i == len(result_dataf):\n",
    "        print(res.publications_url)\n",
    "    else:\n",
    "        print(\"{}\\n\" .format(res.publications_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163.0
    },
    "id": "IbfBeCjqWQRm",
    "outputId": "d6d7c9b2-41f0-4646-feed-dfc8a87fb704"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-05b9873a6a19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfinal_result\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'final_result' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "print_results(final_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UWa0AZiBUFWM"
   },
   "outputs": [],
   "source": [
    "def search(query, dat=None):\n",
    "  result = search_googleish(query)\n",
    "  result = connect_id_df(result, meta)\n",
    "\n",
    "  if dat is not None:\n",
    "    result = filter_date(dat, result)\n",
    "\n",
    "  print_results(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282.0
    },
    "id": "707us3j_UcWv",
    "outputId": "d2ba774c-d28c-46a2-b67a-e889c97ff124"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search for:trump\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "ignored",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-70-1390a74b3f1b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Search for:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msearch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-69-2c3224486f15>\u001b[0m in \u001b[0;36msearch\u001b[0;34m(query, dat)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfilter_date\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mprint_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'print_results' is not defined"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "query = input(\"Search for:\")\n",
    "search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XPinyvDpfnJt"
   },
   "outputs": [],
   "source": [
    "import PySimpleGUI as sg\n",
    "sg.theme_input_text_color('#000000')\n",
    "import os\n",
    "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
    "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0\n",
    "\n",
    "\n",
    "layout = [\n",
    "    [sg.Text(\"Hello\")],\n",
    "    [sg.Button(\"ok\")]\n",
    "]\n",
    "\n",
    "window = sg.Window(\"demo\", layout)\n",
    "\n",
    "while True:\n",
    "  event, values = window.read()\n",
    "\n",
    "  if event == \"ok\" or event == sg.WIN_CLOSED:\n",
    "    break\n",
    "window.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dgh0hfruGpRd"
   },
   "outputs": [],
   "source": [
    "# Interface Code #\n",
    "##\n",
    "val_list = []\n",
    "sg.theme_input_text_color('#000000')\n",
    "\n",
    "layout = [[sg.Text(\"Type a query\")],\n",
    "          [sg.Input(key='query')],\n",
    "          [sg.Button('Search')],\n",
    "          [sg.Text(size=(20,1))],\n",
    "          [sg.Table(values=val_list, headings=[\"Name\", \"Title\", \"publications_url\"], background_color='gray',\n",
    "                    auto_size_columns=False, display_row_numbers=False,justification='left', num_rows=15, col_widths = [5,20,40,100,10,20],\n",
    "                    key='TABLE', row_height=25, enable_events=False)],\n",
    "        [sg.Button('Exit')]]\n",
    "\n",
    "window = sg.Window('Search Engine', layout)\n",
    "\n",
    "while True:\n",
    "    event, values = window.read()\n",
    "\n",
    "    if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
    "        break\n",
    "    \n",
    "    query = values['query']\n",
    "\n",
    "    try:\n",
    "        idx, results = search(index, data, 30, query, \"Name\", \"Title\")\n",
    "        print(results)\n",
    "\n",
    "        window['TABLE'].update(values = results)\n",
    "    except:\n",
    "        print(\"error\")\n",
    "\n",
    "window.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w3jivZJSH4Me"
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PS442bmyH9_y"
   },
   "outputs": [],
   "source": [
    "!pip install PySimpleGUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41rInsnESrfY"
   },
   "outputs": [],
   "source": [
    ""
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "deferal inverted index.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
