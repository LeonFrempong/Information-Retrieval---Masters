{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deferal inverted index.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tPg_-hv_xM6j",
        "outputId": "e1b376d2-93c8-4d1a-86ac-f61e630e029b"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "import glob\n",
        "import pandas as pd\n",
        "#import PySimpleGUI as sg\n",
        "from collections import defaultdict\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import numpy as np\n",
        "from gensim import models\n",
        "\n",
        "!apt-get install -y xvfb # Install X Virtual Frame Buffer\n",
        "import os\n",
        "os.system('Xvfb :1 -screen 0 1600x1200x16  &')    # create virtual display with size 1600x1200 and 16 bit color. Color can be changed to 24 or 8\n",
        "os.environ['DISPLAY']=':1.0'    # tell X clients to use our virtual DISPLAY :1.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZjKdbwVqqUs"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SNqCkYsx5BY",
        "outputId": "f4e50cb0-f613-4155-b404-acfb0966e89b"
      },
      "source": [
        "dataf = pd.read_csv('/content/drive/MyDrive/information retrieval/profileTables.csv')\n",
        "\n",
        "print(dataf.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(19475, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwJY2aR2zVkK",
        "outputId": "a0b7257d-5700-4d3c-8447-4cccc9161b16"
      },
      "source": [
        "datafText= dataf['Title']\n",
        "datafText"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Adaptive Filtering-Based Pseudo Open-Loop Thre...\n",
              "1        Coordinate Transformation-Free Observer-based ...\n",
              "2        Demodulation Type Single-Phase PLL with DC Off...\n",
              "3        Frequency Adaptive Parameter Estimation of Unb...\n",
              "4        Gain Normalized Adaptive Observer For Three-Ph...\n",
              "                               ...                        \n",
              "19470    A Sensitivity Approach for Eliminating Clashes...\n",
              "19471    Using parametric sensitivity analysis to detec...\n",
              "19472               Design Intent for CAD model assemblies\n",
              "19473    Implementing a maths support system for first-...\n",
              "19474    Sensitivity approach for automatically elimina...\n",
              "Name: Title, Length: 19475, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WV4rVdlhzo6l",
        "outputId": "a9f6c9e3-8939-4b60-b289-2361b29696b7"
      },
      "source": [
        "#Eliminating stopwords \n",
        "#this will contain a list of all the words in the corpus\n",
        "\n",
        "datafText_words = []\n",
        "# Tokenize a paragraph into sentences and each sentence in to\n",
        "# words\n",
        "for c in datafText:\n",
        "    for sent in sent_tokenize(c):\n",
        "      word_tokens = word_tokenize(sent)\n",
        "      datafText_words += word_tokens\n",
        "\n",
        "len(datafText)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19475"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2wv4RJX0CWf",
        "outputId": "877e6a79-a212-442d-8a08-486faff8c10e"
      },
      "source": [
        "#inspecting the words in the datafText a bit\n",
        "datafText_words.index('the'), datafText_words.index('The')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(90, 724)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r6MSF4In2dKC",
        "outputId": "2dabfcea-9929-4be3-8f3e-2e083cfb5d2b"
      },
      "source": [
        "datafText_words.index('so'), datafText_words.index('So')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25338, 51760)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4C_IhZQ40pS",
        "outputId": "bb6aa93d-e98f-4846-9108-002fcd3e012e"
      },
      "source": [
        "lower_case_words = set([ x.lower() for x in datafText_words])\n",
        "len(lower_case_words)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjMiWdjo2l5z",
        "outputId": "19f4ea70-e464-48d1-ed90-619b7ba11805"
      },
      "source": [
        "#remove stopwords\n",
        "stwords = set(stopwords.words('english'))\n",
        "#using set difference to calculate stopwords from our words\n",
        "\n",
        "stopfree_words = lower_case_words - stwords\n",
        "len(stopfree_words)\n",
        "\n",
        "\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "23383"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIqR7aOq79qz",
        "outputId": "9384af5e-4f10-45cb-9c15-b3050fe97d31"
      },
      "source": [
        "#Stemming\n",
        "from nltk.stem import snowball\n",
        "\n",
        "stemmer = snowball.SnowballStemmer('english')\n",
        "stemmed_words = set([stemmer.stem(x) for x in stopfree_words])\n",
        "len(stemmed_words)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoRMveQD8F_h",
        "outputId": "38a6ef5b-6abb-4d39-dab9-76c155a4c34e"
      },
      "source": [
        "# Lets look at some of our words\n",
        "list(stemmed_words)[-10:]"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['clockwork',\n",
              " 'project-bas',\n",
              " 'alkalin',\n",
              " 'plastic',\n",
              " 'encyclopaedia',\n",
              " 'wick',\n",
              " 'intuit',\n",
              " 'nb-dope',\n",
              " 'ibigw',\n",
              " 'pneumovirus']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vozWXOKE8KFh",
        "outputId": "b145a0fa-d984-4e09-e572-38940af53bad"
      },
      "source": [
        "#constructing the index\n",
        "# Our index is a map of word -> documents it is found in\n",
        "inverted_index = defaultdict(set)\n",
        "\n",
        "# We maintain the reference to the document by its index in the corpus list\n",
        "for docid, c in enumerate(datafText):\n",
        "    for sent in sent_tokenize(c):\n",
        "        for word in word_tokenize(sent):\n",
        "            word_lower = word.lower()\n",
        "            if word_lower not in stwords:\n",
        "                word_stem = stemmer.stem(word_lower)\n",
        "                # We add the document to the set againt the word in our\n",
        "                # index\n",
        "                inverted_index[word_stem].add(docid)\n",
        "\n",
        "len(inverted_index.keys())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "18003"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2qAzqny8kiY"
      },
      "source": [
        "#searching using the index\n",
        "\n",
        "def operationalSearch(query):\n",
        "    matched_documents = set()\n",
        "    for word in word_tokenize(query):\n",
        "        word_lower = word.lower()\n",
        "        if word_lower not in stwords:\n",
        "            word_stem = stemmer.stem(word_lower)\n",
        "            matches = inverted_index.get(word_stem)\n",
        "            if matches:\n",
        "                # The operator |= is a short hand for set union\n",
        "                matched_documents |= matches\n",
        "    return matched_documents\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B8dJpSkG82r0",
        "outputId": "8899049c-0017-41e1-b9d9-fc864de6d31e"
      },
      "source": [
        "operationalSearch(\"phase\")\n",
        "\n",
        "#the ouput is where the word \"phase\" appears in documents"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{13,\n",
              " 42,\n",
              " 1101,\n",
              " 1113,\n",
              " 1119,\n",
              " 1122,\n",
              " 1925,\n",
              " 1967,\n",
              " 1969,\n",
              " 2271,\n",
              " 2273,\n",
              " 2636,\n",
              " 3139,\n",
              " 3141,\n",
              " 3149,\n",
              " 3150,\n",
              " 3156,\n",
              " 3160,\n",
              " 3166,\n",
              " 3167,\n",
              " 3169,\n",
              " 3173,\n",
              " 3174,\n",
              " 3181,\n",
              " 3196,\n",
              " 3207,\n",
              " 3213,\n",
              " 3226,\n",
              " 3227,\n",
              " 3335,\n",
              " 3337,\n",
              " 3386,\n",
              " 3707,\n",
              " 3970,\n",
              " 4138,\n",
              " 4159,\n",
              " 4185,\n",
              " 4394,\n",
              " 5136,\n",
              " 5142,\n",
              " 5238,\n",
              " 5465,\n",
              " 5552,\n",
              " 5609,\n",
              " 5634,\n",
              " 5635,\n",
              " 5658,\n",
              " 5664,\n",
              " 5775,\n",
              " 5785,\n",
              " 5798,\n",
              " 5805,\n",
              " 5808,\n",
              " 5812,\n",
              " 5975,\n",
              " 5976,\n",
              " 5981,\n",
              " 5987,\n",
              " 6012,\n",
              " 6400,\n",
              " 6423,\n",
              " 6462,\n",
              " 6594,\n",
              " 6596,\n",
              " 6951,\n",
              " 7149,\n",
              " 7495,\n",
              " 7776,\n",
              " 7943,\n",
              " 7950,\n",
              " 8198,\n",
              " 8220,\n",
              " 8223,\n",
              " 8978,\n",
              " 8983,\n",
              " 8984,\n",
              " 8987,\n",
              " 8989,\n",
              " 8994,\n",
              " 8998,\n",
              " 8999,\n",
              " 9041,\n",
              " 9050,\n",
              " 9070,\n",
              " 9077,\n",
              " 9314,\n",
              " 9364,\n",
              " 9562,\n",
              " 9626,\n",
              " 9648,\n",
              " 9978,\n",
              " 10083,\n",
              " 10805,\n",
              " 10948,\n",
              " 11364,\n",
              " 11557,\n",
              " 11933,\n",
              " 12153,\n",
              " 12165,\n",
              " 12351,\n",
              " 12489,\n",
              " 13222,\n",
              " 13229,\n",
              " 13231,\n",
              " 13233,\n",
              " 13414,\n",
              " 14058,\n",
              " 14132,\n",
              " 14253,\n",
              " 15242,\n",
              " 15243,\n",
              " 15864,\n",
              " 16029,\n",
              " 16031,\n",
              " 16059,\n",
              " 16546,\n",
              " 17014,\n",
              " 17019,\n",
              " 17031,\n",
              " 17072,\n",
              " 17295,\n",
              " 17780,\n",
              " 17928,\n",
              " 17929,\n",
              " 17930,\n",
              " 17934,\n",
              " 18079,\n",
              " 18475,\n",
              " 18477,\n",
              " 18500,\n",
              " 18503,\n",
              " 18504}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EsJsMUAO_C16",
        "outputId": "cba3ccfd-c4de-4048-eec3-9bad9c6d0d2a"
      },
      "source": [
        "operationalSearch(\"blue\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{6582, 9716, 12731, 14140}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hW_0wXNuALH3",
        "outputId": "40972e9c-d3e1-45a1-9bc0-39656598a3ae"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.corpus import wordnet\n",
        "from nltk import pos_tag\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import string"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3fdKhO44mUn"
      },
      "source": [
        "record = dataf.loc[0,:].copy()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5kHdEip81H8",
        "outputId": "537c9380-747a-406b-8ede-a58b7da58fa6"
      },
      "source": [
        "record"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Name                                                      Hafiz Ahmed\n",
              "profile_URL         https://pureportal.coventry.ac.uk/en/persons/a...\n",
              "publications_url    https://pureportal.coventry.ac.uk/en/persons/a...\n",
              "Title               Adaptive Filtering-Based Pseudo Open-Loop Thre...\n",
              "Name: 0, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1AOzyB66xnd"
      },
      "source": [
        "def Operationalstring(content):\n",
        "  content = content.lower() #to lowercase\n",
        "  content = content.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
        "  return content"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "_6rlDnPe_yuB",
        "outputId": "8a2fd9a7-51af-4950-f23b-890362faea4d"
      },
      "source": [
        "\n",
        "Operationalstring(record.Title)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'adaptive filteringbased pseudo openloop threephase gridsynchronization technique'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oRvR76A_1gI"
      },
      "source": [
        "\n",
        "def get_wordnet_pos(word):\n",
        "    \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n",
        "    tag = pos_tag([word])[0][1][0].upper()\n",
        "    tag_dict = {\"J\": wordnet.ADJ,\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"V\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(tag, wordnet.NOUN)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R7p-I8tlASK7",
        "outputId": "0bbd041c-1e35-497c-c40b-c8bd4b23269f"
      },
      "source": [
        "print(\"Apple: {}\\n Run: {}\\n Happy: {}\" .format(get_wordnet_pos(\"apple\"), get_wordnet_pos(\"run\"), get_wordnet_pos(\"happy\")))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple: n\n",
            " Run: v\n",
            " Happy: a\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOnG_Q4oAUgI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cec1cf58-734b-40a3-fda5-9760897e65f1"
      },
      "source": [
        "stop = stopwords.words('english')\n",
        "print(stopwords.words('english'))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFXCAYPozisR"
      },
      "source": [
        ""
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPPryvtjzjQu"
      },
      "source": [
        "#################################################################################################"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohsTASUpAXWQ"
      },
      "source": [
        "lem = WordNetLemmatizer()\n",
        "\n",
        "def stopLemmatize(doc):\n",
        "    tokens = nltk.word_tokenize(doc)\n",
        "    tmp = \"\"\n",
        "    for w in tokens:\n",
        "        if w not in stop:\n",
        "            tmp += lem.lemmatize(w, get_wordnet_pos(w)) + \" \"\n",
        "    return tmp"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y24xfASpAc-5",
        "outputId": "ab0b94f0-3fe4-41b7-a4c4-5b5e1b39ba54"
      },
      "source": [
        "stopLemmatize(doc = record.Title)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Adaptive Filtering-Based Pseudo Open-Loop Three-Phase Grid-Synchronization Technique '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SeORviPlAfEA"
      },
      "source": [
        "def Operationalstring(content):\n",
        "  content = content.lower() #to lowercase\n",
        "  content = content.translate(str.maketrans('', '', string.punctuation)) #strip punctuation\n",
        "  content = stopLemmatize(content)\n",
        "  return content"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "uAMysNzCAjSs",
        "outputId": "559073d0-a982-4371-a7e1-69b89e7bdf85"
      },
      "source": [
        "%time Operationalstring(record.Title)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.26 ms, sys: 1.97 ms, total: 4.23 ms\n",
            "Wall time: 4.08 ms\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'adaptive filteringbased pseudo openloop threephase gridsynchronization technique '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hd-8W__sAkwO"
      },
      "source": [
        "meta = dataf.copy()"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBD9U03WAtXQ"
      },
      "source": [
        "def convertDataf(dataf):\n",
        "  dataf['Title'] = dataf['Title'].apply(Operationalstring)\n",
        "  dataf['Name'] = dataf['Name'].apply(Operationalstring)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MxhPtYEUBEHx",
        "outputId": "17031f84-410b-44d3-8eab-9ef2cd782908"
      },
      "source": [
        "%time convertDataf(meta)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 39.8 s, sys: 1.75 s, total: 41.6 s\n",
            "Wall time: 41.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "M7kVQ5JxBGvD",
        "outputId": "bff2597a-97ae-406a-b74a-5627cab8a834"
      },
      "source": [
        "meta.head(5)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>profile_URL</th>\n",
              "      <th>publications_url</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>coordinate transformationfree observerbased ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>demodulation type singlephase pll dc offset re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>frequency adaptive parameter estimation unbala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>https://pureportal.coventry.ac.uk/en/persons/a...</td>\n",
              "      <td>gain normalize adaptive observer threephase sy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Name  ...                                              Title\n",
              "0  hafiz ahmed   ...  adaptive filteringbased pseudo openloop threep...\n",
              "1  hafiz ahmed   ...  coordinate transformationfree observerbased ad...\n",
              "2  hafiz ahmed   ...  demodulation type singlephase pll dc offset re...\n",
              "3  hafiz ahmed   ...  frequency adaptive parameter estimation unbala...\n",
              "4  hafiz ahmed   ...  gain normalize adaptive observer threephase sy...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW4zNcA8BUEi"
      },
      "source": [
        "meta['Text'] = meta['Title'] + \" \" + meta['Name']\n",
        "drop_cols = ['profile_URL', 'publications_url']\n",
        "meta = meta.drop(drop_cols, axis=1)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "iD3aN865ByPl",
        "outputId": "cf0e1052-fa44-4114-a68e-1ecd7c8d91f6"
      },
      "source": [
        "meta.head(5)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
              "      <td>adaptive filteringbased pseudo openloop threep...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>coordinate transformationfree observerbased ad...</td>\n",
              "      <td>coordinate transformationfree observerbased ad...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>demodulation type singlephase pll dc offset re...</td>\n",
              "      <td>demodulation type singlephase pll dc offset re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>frequency adaptive parameter estimation unbala...</td>\n",
              "      <td>frequency adaptive parameter estimation unbala...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>hafiz ahmed</td>\n",
              "      <td>gain normalize adaptive observer threephase sy...</td>\n",
              "      <td>gain normalize adaptive observer threephase sy...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Name  ...                                               Text\n",
              "0  hafiz ahmed   ...  adaptive filteringbased pseudo openloop threep...\n",
              "1  hafiz ahmed   ...  coordinate transformationfree observerbased ad...\n",
              "2  hafiz ahmed   ...  demodulation type singlephase pll dc offset re...\n",
              "3  hafiz ahmed   ...  frequency adaptive parameter estimation unbala...\n",
              "4  hafiz ahmed   ...  gain normalize adaptive observer threephase sy...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N3tVZUvuB3Ce"
      },
      "source": [
        "\n",
        "def convertDataf(dataf):\n",
        "  dataf = dataf\n",
        "  dataf['Title'] = dataf['Title'].apply(Operationalstring)\n",
        "  dataf['Name'] = dataf['Name'].apply(Operationalstring)\n",
        "  dataf['text'] = dataf['Title'] + \" \" + dataf['Name']\n",
        "  drop_cols = ['profile_URL', 'publications_url']\n",
        "  dataf = dataf.drop(drop_cols, axis=1)\n",
        "  return dataf"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoJ9BjpLCmGR"
      },
      "source": [
        "#build index"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk3NflUcCr-4",
        "outputId": "c58cc7f9-09ac-41e4-f861-c513ece1af6a"
      },
      "source": [
        "record = meta.loc[0,:].copy()\n",
        "print(record)\n",
        "testIndex= {}"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Name                                          hafiz ahmed \n",
            "Title    adaptive filteringbased pseudo openloop threep...\n",
            "Text     adaptive filteringbased pseudo openloop threep...\n",
            "Name: 0, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdifoQOfCt9v"
      },
      "source": [
        "words = record.Text.split()\n",
        "Text = record.Text"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83CMiWy2C9mf",
        "outputId": "ce30546e-9941-4b36-fee7-765b0c27b2a2"
      },
      "source": [
        "word = words[0]\n",
        "wordSample = {word: [Text]}\n",
        "print(wordSample)#"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'adaptive': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique  hafiz ahmed ']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "npWAWPUWDDAm"
      },
      "source": [
        "for word in words:\n",
        "  if word in testIndex.keys():\n",
        "    if Text not in testIndex[word]:\n",
        "      testIndex[word].append(word)\n",
        "  else:\n",
        "    testIndex[word] = [word]"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nY8qh6bbDkBe",
        "outputId": "3055b844-2beb-426c-9e8e-4b8c1bbb3733"
      },
      "source": [
        "print(testIndex)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'adaptive': ['adaptive'], 'filteringbased': ['filteringbased'], 'pseudo': ['pseudo'], 'openloop': ['openloop'], 'threephase': ['threephase'], 'gridsynchronization': ['gridsynchronization'], 'technique': ['technique'], 'hafiz': ['hafiz'], 'ahmed': ['ahmed']}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGQpAdiqDoHA"
      },
      "source": [
        "\n",
        "def index_it(record, index):\n",
        "  words = record.Title.split()\n",
        "  Title = record.Title\n",
        "  for word in words:\n",
        "    if word in index.keys():\n",
        "      if Title not in index[word]:\n",
        "        index[word].append(Title)\n",
        "    else:\n",
        "      index[word] = [Title]\n",
        "  return index"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X6yzkF71EZiF",
        "outputId": "87015aa9-ef1a-47a9-a421-f6717c620507"
      },
      "source": [
        "ind = index_it(record=record, index= {})\n",
        "print(ind)\n",
        "print(len(ind))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'adaptive': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'filteringbased': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'pseudo': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'openloop': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'threephase': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'gridsynchronization': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique '], 'technique': ['adaptive filteringbased pseudo openloop threephase gridsynchronization technique ']}\n",
            "7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BAT84bjEb5C"
      },
      "source": [
        "#iterate over all records in the database with scraped publication titles, process them append to index.\n",
        "def indexAll(meta, index):\n",
        "  for i in range(len(meta)):\n",
        "    record = meta.loc[i,:]\n",
        "    index = index_it(record = record, index = index)\n",
        "  return index"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4cyjxn2kEf15",
        "outputId": "fe9d41db-e1e9-4fb5-8323-79006f2139b4"
      },
      "source": [
        "index = indexAll(meta, index = {})\n",
        "len(index)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2XmiZ_bEiSu"
      },
      "source": [
        "def buildIndex(meta, index):\n",
        "    to_add = convertDataf(dataf)\n",
        "    index = indexAll(meta = to_add, index = index)\n",
        "    return index"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTpFdmHgE_Dj"
      },
      "source": [
        "idx = buildIndex(meta = dataf, index = {})"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGM-dn6SFEsP",
        "outputId": "9044a00c-5606-4057-d69d-82500abefbe5"
      },
      "source": [
        "len(idx)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19835"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtFSBJnQGANr"
      },
      "source": [
        "import json\n",
        "\n",
        "with open(\"/content/drive/MyDrive/information retrieval/7071CEM Information Retrieval/CW/New folder/pureportal_survey_json.json\", 'w') as fp:\n",
        "    json.dump(idx, fp, sort_keys=True, indent=4)"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iLKbiGJLGg3B"
      },
      "source": [
        "with open('/content/drive/MyDrive/information retrieval/7071CEM Information Retrieval/CW/New folder/pureportal_survey_json.json', 'r') as f:\n",
        "    pureportal_survey_json = json.load(f)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lQ9d65YDbYy8"
      },
      "source": [
        "word2vec = pureportal_survey_json"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPz4Pg0kLRM8",
        "outputId": "d9ff2d9a-d969-45b8-b3c5-06db5b83a515"
      },
      "source": [
        "print(words)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['adaptive', 'filteringbased', 'pseudo', 'openloop', 'threephase', 'gridsynchronization', 'technique', 'hafiz', 'ahmed']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVotaq36_Pxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c690ee88-4492-4908-f0c1-2c57804b462c"
      },
      "source": [
        "\n",
        "# Python program to generate word vectors using Word2Vec\n",
        "  \n",
        "# importing all necessary modules\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "import gensim\n",
        "import warnings\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooYh-oG9_SHe"
      },
      "source": [
        "#################################################################################\n",
        "#query processor"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJeeTBWKLb_B"
      },
      "source": [
        "check = \"filtering based\""
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NiQFjQTPLn-c",
        "outputId": "6a98ad9d-9a8f-401d-d1e9-8181b4fba8da"
      },
      "source": [
        "print(\"User query: {}.\" .format(check))\n",
        "normTest = Operationalstring(check)\n",
        "print(\"Normalized query: {}.\" .format(normTest))"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "User query: filtering based.\n",
            "Normalized query: filter base .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCga9nmKLvcR"
      },
      "source": [
        "checkSplit = normTest.split()"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiYL5Qw7L1Pp"
      },
      "source": [
        "def operationQuery(query):\n",
        "  norm = Operationalstring(query)\n",
        "  return norm.split()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VocpqwHPL1V_"
      },
      "source": [
        "#retreive from index\n",
        "retrieved = []\n",
        "for word in checkSplit:\n",
        "  if word in index.keys():\n",
        "    retrieved.append(index[word])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fxomh_a0MBhZ"
      },
      "source": [
        "#looking for intersection of all posting lists\n",
        "def intersectLists(lists):\n",
        "  intersect = list(set.intersection(*map(set, lists)))\n",
        "  intersect.sort()\n",
        "  return intersect"
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fpeDei4sME1y",
        "outputId": "13de0266-8a21-44df-f91f-a32eb987f4c7"
      },
      "source": [
        "outcome = intersectLists(retrieved)\n",
        "print(outcome)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['information fusion algorithm vehicle state estimation base extend kalman filter ', 'numerical achieve extend kalman filter state observer design base vehicle model contain unitire model ', 'state charge estimation lithiumion battery base intelligent adaptive unscented kalman filter ', 'vehicle drive state estimation base extend kalman filter ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwhJ1QEBMPKY"
      },
      "source": [
        "def googleishSearch(query, index=idx):\n",
        " splitQuery = operationQuery(query)\n",
        " retrieved = []\n",
        " for term in splitQuery:\n",
        "  if term in index.keys():\n",
        "    retrieved.append(index[term])\n",
        " if len(retrieved)>0:\n",
        "  outcome = intersectLists(retrieved)\n",
        " else:\n",
        "    outcome = [0]\n",
        " return outcome"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m2JapAfMTWA",
        "outputId": "004d9c3c-9631-4288-ee48-19f352020be4"
      },
      "source": [
        "outcome_IDs = googleishSearch(\"historical\", index)\n",
        "print(outcome_IDs)\n",
        "print(len(outcome_IDs))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['advertising public memory social cultural historical perspective ghost sign ', 'britain islamic diaspora historical précis neoteric ethnography british muslim ', 'decommonising mind historical impact british imperialism indigenous tenure system selfunderstanding highland island scotland ', 'enlightenment historical write expulsion england ’ jew ', 'four eponym sunni islamic jurisprudence examination historical development dominant madhâhib polemic ijtihâd versus taqlîd ', 'hisql frontend query system historical database ', 'historical institutionalist perspective persistence state control financial sector reform insightful case myanmar ', 'historical pollution human right violation role criminal law ', 'historical pollution longterm liability global challenge need international approach ', 'historical write britain 16881830 vision history ', 'impact select historical event incomebased distribution terrorism rise fundamentalist terrorism iraq war ', 'international law islam historical exploration ', 'introduction procopius caesarea literary historical interpretation ', 'mapping field 40 year historical review ', 'native american racism age donald trump historical contemporary perspective ', 'procopius caesarea literary historical interpretation ', 'reconstruct battle battlefield scientific solution historical problem bannockburn scotland ', 'relational mobility predicts social behavior 39 country tie historical farm threat ', 'religion high education europe north america historical contemporary context ', 'wittgenstein ’ philosophy psychology interpretation application historical context ']\n",
            "20\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--zTAgIJMaqp"
      },
      "source": [
        "#Retrieve meta-data"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_Slc1m6Mwt6"
      },
      "source": [
        "#Query from database to get only rows of outcome IDs\n",
        "\n",
        "def connectIDdataf(retrieved_id, dataf):\n",
        "    return dataf[dataf.Title.isin(retrieved_id)].reset_index(drop=True)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205
        },
        "id": "faDqcHBGM6qB",
        "outputId": "6f5300ba-afba-4843-81f9-094b4f89ff14"
      },
      "source": [
        "result_meta = connectIDdataf(outcome_IDs, meta)\n",
        "result_meta.head(5)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Name</th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>rachid anane</td>\n",
              "      <td>hisql frontend query system historical database</td>\n",
              "      <td>hisql frontend query system historical databas...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>kristin aune</td>\n",
              "      <td>religion high education europe north america h...</td>\n",
              "      <td>religion high education europe north america h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>megan crawford</td>\n",
              "      <td>mapping field 40 year historical review</td>\n",
              "      <td>mapping field 40 year historical review  megan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>benjamin dew</td>\n",
              "      <td>enlightenment historical write expulsion engla...</td>\n",
              "      <td>enlightenment historical write expulsion engla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>benjamin dew</td>\n",
              "      <td>historical write britain 16881830 vision history</td>\n",
              "      <td>historical write britain 16881830 vision histo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              Name  ...                                               Text\n",
              "0    rachid anane   ...  hisql frontend query system historical databas...\n",
              "1    kristin aune   ...  religion high education europe north america h...\n",
              "2  megan crawford   ...  mapping field 40 year historical review  megan...\n",
              "3    benjamin dew   ...  enlightenment historical write expulsion engla...\n",
              "4    benjamin dew   ...  historical write britain 16881830 vision histo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "707us3j_UcWv",
        "outputId": "6ac58ec4-74d5-4089-d9c2-fb85f4f10921"
      },
      "source": [
        "query = input(\"Search for:\")\n",
        "googleishSearch(query)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search for:filtering\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['384 tmacs fir filter artix7 fpga use prism signal processing ',\n",
              " 'bearing natural degradation detection gearbox comparative study effectiveness adaptive filter algorithm spectral kurtosis ',\n",
              " 'box regularize particle filter state estimation severely ambiguous nonlinear measurement ',\n",
              " 'building billion tap filter ',\n",
              " 'comparative study adaptive filter detect naturally degrade bearing within gearbox ',\n",
              " 'comparative study effectiveness adaptive filter algorithm spectral kurtosis linear prediction detection naturally degrade bearing gearbox ',\n",
              " 'conditional filter reduction search space genetic algorithm optimisation sensor actuator location active vibration control ',\n",
              " 'critical comparison attitude estimation gaussian approximate filter coordinatefree dual optimal control ',\n",
              " 'dual extend kalman filter combine estimation vehicle state road friction ',\n",
              " 'effect gridfilter width definition implicitly filter large eddy simulation use openfoam ',\n",
              " 'effectiveness adaptive filter algorithm spectral kurtosis bearing fault detection gearbox ',\n",
              " 'enhancement generalize integratorbased adaptive filter dynamic tune range ',\n",
              " 'epic body filter past embody present – performer ’ perspective ',\n",
              " 'estimation vehicle state tireroad friction use parallel extend kalman filter ',\n",
              " 'evaluation effectiveness wrap filter drain pipe geotextile pollution prevention response relatively large oil release ',\n",
              " 'evaluation smooth filter gas sensor signal cleaning ',\n",
              " 'experimental model study role ar addition work gas development intrinsic stress tin coating produce filter vacuumarc plasma ',\n",
              " 'explore effect geotextiles performance highway filter drain sustainable resilient highway drainage ',\n",
              " 'facile fabrication recyclable superhydrophobic oleophilic sorbent waste cigarette filter sequestration oil pollutant aqueous environment ',\n",
              " 'fast retrieval time series use multiresolution filter multiple reduce space ',\n",
              " 'game theory minimax filter design indoor position track system use visible light communication ',\n",
              " 'gasoline particulate filter wall permeability test ',\n",
              " 'household slow sand filter intermittent continuous flow treat water contain low mineral ion concentration bisphenol ',\n",
              " 'impact slowrelease fertilizer struvite enhancement biodegradation filter drain prevent groundwater pollution ',\n",
              " 'impact slowrelease fertilizer struvite enhancement biodegradation hydrocarbon filter drain prevent groundwater pollution ',\n",
              " 'information fusion algorithm vehicle state estimation base extend kalman filter ',\n",
              " 'innovation really bring economic growth role social filter china ',\n",
              " 'investigation effect slowrelease fertilizer struvite biodegradation filter drain potential application treat water irrigation road verge ',\n",
              " 'jumpmarkov regularize particle filter estimation ambiguous sensor fault ',\n",
              " 'low cost low pas prism filter ',\n",
              " 'lowpass filter gain tune free simple dc offset rejection technique single threephase system ',\n",
              " 'method system ultranarrowband filter signal processing use concept call prism ',\n",
              " 'model couple catalyst particulate filter gasoline direct injection engine ',\n",
              " 'model pressure loss gasoline particulate filter high flow regime temperature ',\n",
              " 'model tune circular limit cycle oscillator fll preloop filter ',\n",
              " 'multichannel model approach particulate filter ',\n",
              " 'new model apply extend kalman filter extract harmonic signal noisy measurement ',\n",
              " 'numerical achieve extend kalman filter state observer design base vehicle model contain unitire model ',\n",
              " 'optimal filter design power electronic converter ',\n",
              " 'optimize vehicle dynamic virtual sense use metaheuristic optimization unscented kalman filter ',\n",
              " 'phasor estimation grid power monitoring least square v linear kalman filter ',\n",
              " 'predictive data reduction wireless sensor network use selective filter ',\n",
              " 'predictive data reduction wireless sensor network use selective filter engine monitoring ',\n",
              " 'realtime rejection ammonia cross sensitivity sensor diesel aftertreatment system parallel particle filter ',\n",
              " 'simulation hydraulic performance highway filter drain laboratory model stormwater management tool ',\n",
              " 'simultaneous actuator sensor fault estimation aircraft use jumpmarkov regularize particle filter ',\n",
              " 'social filter innovation growth empirical evidence china ',\n",
              " 'speedingup similarity search time series database couple dimensionality reduction technique fastanddirty filter ',\n",
              " 'state charge estimation lithiumion battery base intelligent adaptive unscented kalman filter ',\n",
              " 'suboptimal anisotropic filter linear discrete nonstationary system uncentered external disturbance ',\n",
              " 'turbulent flow pressure loss gasoline particulate filter ',\n",
              " 'vehicle drive state estimation base extend kalman filter ',\n",
              " 'vehicle dynamic virtual sense use unscented kalman filter simulation experiment driverintheloop setup ',\n",
              " 'wavelet transform smooth filter metal oxide gas sensor signal cleaning ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgh0hfruGpRd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "65439ead-c475-40ce-c9e0-f53ddf331bde"
      },
      "source": [
        "# Interface Code #\n",
        "##\n",
        "val_list = []\n",
        "sg.theme_input_text_color('#000000')\n",
        "\n",
        "layout = [[sg.Text(\"Type a query\")],\n",
        "          [sg.Input(key='query')],\n",
        "          [sg.Button('Search')],\n",
        "          [sg.Text(size=(20,1))],\n",
        "          [sg.Table(values=val_list, headings=[\"Name\", \"Title\", \"publications_url\"], background_color='gray',\n",
        "                    auto_size_columns=False, display_row_numbers=False,justification='left', num_rows=15, col_widths = [5,20,40,100,10,20],\n",
        "                    key='TABLE', row_height=25, enable_events=False)],\n",
        "        [sg.Button('Exit')]]\n",
        "\n",
        "window = sg.Window('Search Engine', layout)\n",
        "\n",
        "while True:\n",
        "    event, values = window.read()\n",
        "\n",
        "    if event == sg.WINDOW_CLOSED or event == 'Exit':\n",
        "        break\n",
        "    \n",
        "    query = values['query']\n",
        "\n",
        "    try:\n",
        "        idx, results = search(index, data, 30, query, \"Name\", \"Title\")\n",
        "        print(results)\n",
        "\n",
        "        window['TABLE'].update(values = results)\n",
        "    except:\n",
        "        print(\"error\")\n",
        "\n",
        "window.close()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-8ea8a27e06c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m##\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mval_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtheme_input_text_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'#000000'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m layout = [[sg.Text(\"Type a query\")],\n",
            "\u001b[0;31mNameError\u001b[0m: name 'sg' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3jivZJSH4Me"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PS442bmyH9_y"
      },
      "source": [
        "!pip install PySimpleGUI"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41rInsnESrfY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}